{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1c85545c",
      "metadata": {
        "id": "1c85545c"
      },
      "source": [
        "# Отключаем сообщения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4a6f0f7a",
      "metadata": {
        "id": "4a6f0f7a"
      },
      "outputs": [],
      "source": [
        "from transformers import logging\n",
        "logging.set_verbosity_error() # set_verbosity_warning()\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5093f156",
      "metadata": {
        "id": "5093f156"
      },
      "source": [
        "# Чанки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "3bad9b1f",
      "metadata": {
        "id": "3bad9b1f"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import TextLoader, Docx2txtLoader, PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chat_models.gigachat import GigaChat\n",
        "\n",
        "def file_to_chunks(file_name, sep, chunk_size, chunk_overlap):\n",
        "    file_ext = file_name.split('.')[-1]\n",
        "    file_path = f'{TEST_FOLDER_PATH}/{file_name}'\n",
        "\n",
        "    # Загружаем содержимое файла\n",
        "    if file_ext == 'txt':\n",
        "        loader = TextLoader(file_path, encoding='utf-8')\n",
        "    elif file_ext == 'docx':\n",
        "        loader = Docx2txtLoader(file_path)\n",
        "    elif file_ext == 'pdf':\n",
        "        loader = PyPDFLoader(file_path)\n",
        "    else:\n",
        "        return\n",
        "    file = loader.load()\n",
        "    content = file[0].page_content\n",
        "\n",
        "    # Разбиваем текст на чанки\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        separators = sep,\n",
        "        chunk_size = chunk_size,\n",
        "        chunk_overlap = chunk_overlap,\n",
        "        length_function = len,\n",
        "        is_separator_regex = False,\n",
        "        add_start_index = False\n",
        "    )\n",
        "    chunks = text_splitter.split_text(content)\n",
        "\n",
        "    return chunks"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22717781",
      "metadata": {
        "id": "22717781"
      },
      "source": [
        "# Bi-encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "f15ff086",
      "metadata": {
        "id": "f15ff086"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sentence_transformers.models import Pooling, Transformer\n",
        "\n",
        "# Подгружаем bi-encoder\n",
        "def get_bi_encoder(bi_encoder_name):\n",
        "    raw_model = Transformer(model_name_or_path=f'{bi_encoder_name}')\n",
        "\n",
        "    # Вытаскиваем размер векторов\n",
        "    bi_encoder_dim = raw_model.get_word_embedding_dimension()\n",
        "\n",
        "    pooling_model = Pooling(\n",
        "        bi_encoder_dim,\n",
        "        pooling_mode_cls_token = False,\n",
        "        pooling_mode_mean_tokens = True\n",
        "    )\n",
        "    bi_encoder = SentenceTransformer(\n",
        "        modules = [raw_model, pooling_model],\n",
        "        device = 'cuda' # помещаем его на GPU\n",
        "    )\n",
        "\n",
        "    return bi_encoder, bi_encoder_dim\n",
        "\n",
        "# Формируем из строки вектор\n",
        "def str_to_vec(bi_encoder, text):\n",
        "    embeddings = bi_encoder.encode(\n",
        "        text,\n",
        "        convert_to_tensor = False,\n",
        "        show_progress_bar = False\n",
        "    )\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "980eafad",
      "metadata": {
        "id": "980eafad"
      },
      "source": [
        "# Qdrant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "c5fd1d4c",
      "metadata": {
        "id": "c5fd1d4c"
      },
      "outputs": [],
      "source": [
        "import uuid\n",
        "\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.http.models import Distance, VectorParams, PointStruct\n",
        "\n",
        "\n",
        "# Создаем подключение к векторной БД\n",
        "qdrant_client = QdrantClient(':memory:')\n",
        "\n",
        "# Помещаем чанки и доп. информаицю в векторую БД\n",
        "def save_chunks(bi_encoder, chunks, file_name):\n",
        "    # Конвертируем чанки в векитора\n",
        "    chunk_embeddings = str_to_vec(bi_encoder, chunks)\n",
        "\n",
        "    # Содаем объект(ы) для БД\n",
        "    points = []\n",
        "    for i in range(len(chunk_embeddings)):\n",
        "        point = PointStruct(\n",
        "            id=str(uuid.uuid4()), # генерируем GUID\n",
        "            vector = chunk_embeddings[i],\n",
        "            payload={'file': file_name, 'chunk': chunks[i]}\n",
        "        )\n",
        "        points.append(point)\n",
        "\n",
        "    # Сохраняем вектора в БД\n",
        "    operation_info = qdrant_client.upsert(\n",
        "        collection_name = COLL_NAME,\n",
        "        wait = True,\n",
        "        points = points\n",
        "    )\n",
        "\n",
        "    return operation_info\n",
        "\n",
        "def files_to_vecdb(files, bi_encoder, vec_size, sep, chunk_size, chunk_overlap):\n",
        "    # Удаляем и заново создаем коллекцию\n",
        "    qdrant_client.delete_collection(collection_name=COLL_NAME)\n",
        "    qdrant_client.create_collection(\n",
        "        collection_name = COLL_NAME,\n",
        "        vectors_config = VectorParams(size=vec_size, distance=Distance.COSINE),\n",
        "    )\n",
        "\n",
        "    # Каждый файл по одному...\n",
        "    for file_name in files:\n",
        "        # делим на чанки ...\n",
        "        chunks = file_to_chunks(file_name, sep, chunk_size, chunk_overlap)\n",
        "        # помещаем чанки в векторную БД\n",
        "        operation_status = save_chunks(bi_encoder, chunks, file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64591a76",
      "metadata": {
        "id": "64591a76"
      },
      "source": [
        "# Поиск векторов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "303237f9",
      "metadata": {
        "id": "303237f9"
      },
      "outputs": [],
      "source": [
        "def vec_search(bi_encoder, query, n_top_cos):\n",
        "    # Кодируем запрос в вектор\n",
        "    query_emb = str_to_vec(bi_encoder, query)\n",
        "\n",
        "    # Поиск в БД\n",
        "    search_result = qdrant_client.search(\n",
        "        collection_name = COLL_NAME,\n",
        "        query_vector = query_emb,\n",
        "        limit = n_top_cos,\n",
        "        with_vectors = False\n",
        "    )\n",
        "\n",
        "    top_chunks = [x.payload['chunk'] for x in search_result]\n",
        "    top_files = list(set([x.payload['file'] for x in search_result]))\n",
        "\n",
        "    return top_chunks, top_files"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5129bd1",
      "metadata": {
        "id": "b5129bd1"
      },
      "source": [
        "# LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "4efdfed8",
      "metadata": {
        "id": "4efdfed8"
      },
      "outputs": [],
      "source": [
        "llm = GigaChat(credentials='OGMwNTUyMzktMjM0Ny00MDIxLThiZWQtNDlkY2E3ODkxOTk5OmIyNTI4MDQ3LTEyNzQtNGIzMy1iZGNkLTNkNzg4MDEyZWY4Mg==',\n",
        "                verify_ssl_certs=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "838aa1c6",
      "metadata": {
        "id": "838aa1c6"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "def get_llm_answer(query, chunks_join, max_new_tokens, temperature, top_p, top_k):\n",
        "    user_prompt = '''Ты структурированно отвечаешь на вопрос на основе контекста.\n",
        "    Предлагай пользователю задать дополнительные похожие вопросы. Предлагай контекстную и справочную информацию,\n",
        "    основываясь на метаданных каждого документа из контекста.\n",
        "    Если ответа на вопрос нет в контексте, сообщи об этом.\n",
        "    Контекст: {chunks_join}\n",
        "    Вопрос: {query}\n",
        "    Ответ:'''.format(chunks_join=chunks_join, query=query)\n",
        "\n",
        "    SYSTEM_PROMPT = \"Ты — Гигачат, русскоязычный автоматический ассистент. Ты разговариваешь с людьми и помогаешь им.\"\n",
        "\n",
        "    # Объединяем системный и пользовательский промпт в корректном формате\n",
        "    messages = [[SystemMessage(content=SYSTEM_PROMPT), HumanMessage(content=user_prompt)]]\n",
        "\n",
        "    # Используем модель llm для получения ответа\n",
        "    response = llm.generate(\n",
        "        messages=messages,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "        top_k=top_k\n",
        "    )\n",
        "\n",
        "    return response.generations[0][0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ee2b00a",
      "metadata": {
        "id": "4ee2b00a"
      },
      "source": [
        "# Оценка"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "82c47773",
      "metadata": {
        "id": "82c47773"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import json\n",
        "from rouge import Rouge\n",
        "from pymorphy3 import MorphAnalyzer\n",
        "\n",
        "f = open('/content/drive/MyDrive/documents/RAG/research/stopwords-ru.json', encoding='utf-8')\n",
        "stop_words = json.load(f)\n",
        "#print(stop_words)\n",
        "\n",
        "morph = MorphAnalyzer()\n",
        "patterns = \"[«»°!#$%&'()*+,./:;<=>?@[\\]^_`{|}~—\\\"\\-]+\"\n",
        "\n",
        "def lemmatize(string):\n",
        "    clear = re.sub(patterns, ' ', string)\n",
        "    tokens = []\n",
        "    for token in clear.split():\n",
        "        if token:\n",
        "            token = token.strip()\n",
        "            token = morph.normal_forms(token)[0]\n",
        "            if token not in stop_words:\n",
        "                tokens.append(token)\n",
        "    tokens = ' '.join(tokens)\n",
        "    return tokens\n",
        "\n",
        "def get_llm_score(answer, answer_true):\n",
        "    answer = lemmatize(answer)\n",
        "    answer_true = lemmatize(answer_true)\n",
        "    if len(answer) == 0:\n",
        "        answer = '-'\n",
        "\n",
        "    rouge = Rouge()\n",
        "    scores = rouge.get_scores(answer, answer_true)[0]\n",
        "    rouge_1 = round(scores['rouge-1']['r']*100, 2)\n",
        "\n",
        "    return rouge_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "5f5568c3",
      "metadata": {
        "id": "5f5568c3"
      },
      "outputs": [],
      "source": [
        "def get_context_score(chunks_join, context):\n",
        "    rouge = Rouge()\n",
        "    scores = rouge.get_scores(chunks_join, context)[0]\n",
        "    score = round(scores['rouge-l']['r'] * 100)\n",
        "    return score"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3675447",
      "metadata": {
        "id": "c3675447"
      },
      "source": [
        "# Выполнение теста"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "0d9cfa36",
      "metadata": {
        "id": "0d9cfa36"
      },
      "outputs": [],
      "source": [
        "def run_one_test(df, encoder_name, sep, chunk_size, chunk_overlap, n_top_cos, max_new_tokens, temperature, top_p, top_k):\n",
        "    bi_encoder, vec_size = get_bi_encoder(encoder_name)\n",
        "\n",
        "    files = df['Файл'].unique()\n",
        "    files_to_vecdb(files, bi_encoder, vec_size, sep, chunk_size, chunk_overlap)\n",
        "\n",
        "    result = []\n",
        "    for i, row in df.iterrows():\n",
        "        query = row['Вопрос']\n",
        "        answer_true = row['Правильный ответ']\n",
        "        file_name = row['Файл']\n",
        "        context = row['Контекст']\n",
        "\n",
        "        # Проверка типов\n",
        "        if not isinstance(query, str):\n",
        "            print(f\"Неправильный тип для 'Вопрос' в строке {i}: {query}\")\n",
        "            continue\n",
        "        if not isinstance(answer_true, str):\n",
        "            print(f\"Неправильный тип для 'Правильный ответ' в строке {i}: {answer_true}\")\n",
        "            continue\n",
        "        if not isinstance(file_name, str):\n",
        "            print(f\"Неправильный тип для 'Файл' в строке {i}: {file_name}\")\n",
        "            continue\n",
        "        if not isinstance(context, str):\n",
        "            print(f\"Неправильный тип для 'Контекст' в строке {i}: {context}\")\n",
        "            continue\n",
        "\n",
        "        top_chunks, top_files = vec_search(bi_encoder, query, n_top_cos)\n",
        "\n",
        "        # Проверка типов для top_chunks\n",
        "        if not all(isinstance(chunk, str) for chunk in top_chunks):\n",
        "            print(f\"Некорректные данные в top_chunks для запроса '{query}': {top_chunks}\")\n",
        "            continue\n",
        "\n",
        "        row['top_files'] = top_files\n",
        "        row['top_chunks'] = top_chunks\n",
        "        top_chunks_join = '\\n'.join(top_chunks)  # объединяем чанки\n",
        "\n",
        "        answer = get_llm_answer(query, top_chunks_join, max_new_tokens, temperature, top_p, top_k)\n",
        "        row['Ответ'] = answer\n",
        "        #print(answer)\n",
        "        row['file_score'] = int(file_name in top_files)\n",
        "        row['context_score'] = get_context_score(top_chunks_join, context)\n",
        "        row['llm_score'] = get_llm_score(answer, answer_true)\n",
        "\n",
        "        result.append(row)\n",
        "\n",
        "    result = pd.DataFrame(result)\n",
        "    result = result.sort_values(by=['llm_score','context_score','file_score'], ascending=False)\n",
        "    result = result.reset_index(drop=True)\n",
        "\n",
        "    score = result['llm_score'].mean()\n",
        "\n",
        "    return result, score\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "086d62a6",
      "metadata": {
        "id": "086d62a6"
      },
      "source": [
        "# Запуск Optuna'ы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "b8ba0c41",
      "metadata": {
        "id": "b8ba0c41"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "\n",
        "def objective(trial):\n",
        "    global best_score, best_result\n",
        "\n",
        "    encoder_name = trial.suggest_categorical('encoder_name', ['cointegrated/rubert-tiny2',\n",
        "                                                              'sentence-transformers/paraphrase-multilingual-mpnet-base-v2'])\n",
        "    sep = trial.suggest_categorical('sep', ['.',' ','\\n'])\n",
        "\n",
        "    chunk_size = trial.suggest_int('chunk_size', 600, 2000)\n",
        "    chunk_overlap = trial.suggest_int('chunk_overlap', 100, 600)\n",
        "    n_top_cos = trial.suggest_int('n_top_cos', 1, 8)\n",
        "\n",
        "    max_new_tokens = trial.suggest_int('max_new_tokens', 100, 1000)\n",
        "    temperature = trial.suggest_float('temperature', 0.01, 0.99)\n",
        "    top_p = trial.suggest_float('top_p', 0.01, 0.99)\n",
        "    top_k = trial.suggest_int('top_k', 10, 150)\n",
        "\n",
        "    result, score = run_one_test(\n",
        "        TEST_DF,\n",
        "        encoder_name,\n",
        "        sep, chunk_size, chunk_overlap, n_top_cos,\n",
        "        max_new_tokens, temperature, top_p, top_k\n",
        "    )\n",
        "\n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "        best_score_tag = ' <--'\n",
        "        best_result = result\n",
        "    else:\n",
        "        best_score_tag = ''\n",
        "\n",
        "    print(f'{score:.2f}', best_score_tag)\n",
        "\n",
        "    return score\n",
        "\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "COLL_NAME = 'optuna_my_test'\n",
        "TEST_FILE_PATH = '/content/drive/MyDrive/documents/RAG/research/ru_rag_test_dataset.pkl'\n",
        "TEST_FOLDER_PATH = '/content/drive/MyDrive/documents/RAG/research/files'\n",
        "\n",
        "TEST_DF = pd.read_pickle(TEST_FILE_PATH)[::15]\n",
        "print('Кол-во строк:', TEST_DF.shape[0])\n",
        "\n",
        "\n",
        "best_score = 0\n",
        "best_result = None\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=500, timeout=60*60*24)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JpYm74tyER8m",
        "outputId": "c9160790-c669-4256-ad80-3b32327dc8a2"
      },
      "id": "JpYm74tyER8m",
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Кол-во строк: 62\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44.51  <--\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55.32  <--\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47.80 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30.78 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43.58 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58.06  <--\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:gigachat.client:AUTHENTICATION ERROR\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36.50 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44.47 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45.56 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64.52  <--\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51.22 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62.61 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n",
            "WARNING:langchain_community.chat_models.gigachat:Giga generation stopped with reason: blacklist\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "66.82  <--\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[W 2024-09-29 15:56:14,550] Trial 13 failed with parameters: {'encoder_name': 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2', 'sep': '.', 'chunk_size': 1029, 'chunk_overlap': 395, 'n_top_cos': 5, 'max_new_tokens': 640, 'temperature': 0.34038345242780205, 'top_p': 0.3891060559861204, 'top_k': 95} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-28-630db696cb3e>\", line 19, in objective\n",
            "    result, score = run_one_test(\n",
            "  File \"<ipython-input-90-82390a89dbad>\", line 5, in run_one_test\n",
            "    files_to_vecdb(files, bi_encoder, vec_size, sep, chunk_size, chunk_overlap)\n",
            "  File \"<ipython-input-38-460df63645d5>\", line 47, in files_to_vecdb\n",
            "    operation_status = save_chunks(bi_encoder, chunks, file_name)\n",
            "  File \"<ipython-input-38-460df63645d5>\", line 13, in save_chunks\n",
            "    chunk_embeddings = str_to_vec(bi_encoder, chunks)\n",
            "  File \"<ipython-input-36-ee2e818356d6>\", line 25, in str_to_vec\n",
            "    embeddings = bi_encoder.encode(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sentence_transformers/SentenceTransformer.py\", line 630, in encode\n",
            "    embeddings = embeddings.cpu()\n",
            "KeyboardInterrupt\n",
            "[W 2024-09-29 15:56:14,552] Trial 13 failed with value None.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-9eefe3cdbd46>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     ):\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-630db696cb3e>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mtop_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'top_k'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     result, score = run_one_test(\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mTEST_DF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mencoder_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-90-82390a89dbad>\u001b[0m in \u001b[0;36mrun_one_test\u001b[0;34m(df, encoder_name, sep, chunk_size, chunk_overlap, n_top_cos, max_new_tokens, temperature, top_p, top_k)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Файл'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mfiles_to_vecdb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbi_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvec_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_overlap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-460df63645d5>\u001b[0m in \u001b[0;36mfiles_to_vecdb\u001b[0;34m(files, bi_encoder, vec_size, sep, chunk_size, chunk_overlap)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_to_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_overlap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# помещаем чанки в векторную БД\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0moperation_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbi_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-38-460df63645d5>\u001b[0m in \u001b[0;36msave_chunks\u001b[0;34m(bi_encoder, chunks, file_name)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbi_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Конвертируем чанки в векитора\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mchunk_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr_to_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbi_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Содаем объект(ы) для БД\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-ee2e818356d6>\u001b[0m in \u001b[0;36mstr_to_vec\u001b[0;34m(bi_encoder, text)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Формируем из строки вектор\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstr_to_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbi_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     embeddings = bi_encoder.encode(\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mconvert_to_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    628\u001b[0m                     \u001b[0;31m# fixes for #522 and #487 to avoid oom problems on gpu with large datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mconvert_to_numpy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m                         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mall_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opuna_df = study.trials_dataframe()\n",
        "opuna_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 891
        },
        "id": "v65watTrErgp",
        "outputId": "bac5009b-146a-4947-eb16-2283d02a17a0"
      },
      "id": "v65watTrErgp",
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    number      value             datetime_start          datetime_complete  \\\n",
              "0        0  44.508548 2024-09-29 15:33:43.639050 2024-09-29 15:34:46.717970   \n",
              "1        1  55.324839 2024-09-29 15:34:46.718298 2024-09-29 15:35:55.938448   \n",
              "2        2  47.795806 2024-09-29 15:35:55.938873 2024-09-29 15:37:02.157081   \n",
              "3        3  30.775806 2024-09-29 15:37:02.157319 2024-09-29 15:38:09.290714   \n",
              "4        4  43.579032 2024-09-29 15:38:09.290954 2024-09-29 15:39:31.353000   \n",
              "5        5  58.064516 2024-09-29 15:39:31.353421 2024-09-29 15:41:28.949359   \n",
              "6        6  36.497742 2024-09-29 15:41:28.949619 2024-09-29 15:42:44.628772   \n",
              "7        7  44.472097 2024-09-29 15:42:44.629041 2024-09-29 15:44:39.669284   \n",
              "8        8  45.559032 2024-09-29 15:44:39.669593 2024-09-29 15:46:34.648044   \n",
              "9        9  64.518387 2024-09-29 15:46:34.648310 2024-09-29 15:49:41.909430   \n",
              "10      10  51.215645 2024-09-29 15:49:41.909749 2024-09-29 15:51:53.530972   \n",
              "11      11  62.606613 2024-09-29 15:51:53.531209 2024-09-29 15:53:57.680767   \n",
              "12      12  66.822419 2024-09-29 15:53:57.681160 2024-09-29 15:56:07.388938   \n",
              "13      13        NaN 2024-09-29 15:56:07.389207 2024-09-29 15:56:14.550017   \n",
              "\n",
              "                 duration  params_chunk_overlap  params_chunk_size  \\\n",
              "0  0 days 00:01:03.078920                   110               1653   \n",
              "1  0 days 00:01:09.220150                   521               1593   \n",
              "2  0 days 00:01:06.218208                   469                751   \n",
              "3  0 days 00:01:07.133395                   134               1425   \n",
              "4  0 days 00:01:22.062046                   566                706   \n",
              "5  0 days 00:01:57.595938                   105                744   \n",
              "6  0 days 00:01:15.679153                   571                669   \n",
              "7  0 days 00:01:55.040243                   299               1363   \n",
              "8  0 days 00:01:54.978451                   198               1683   \n",
              "9  0 days 00:03:07.261120                   538                722   \n",
              "10 0 days 00:02:11.621223                   415               1052   \n",
              "11 0 days 00:02:04.149558                   316               1039   \n",
              "12 0 days 00:02:09.707778                   330               1029   \n",
              "13 0 days 00:00:07.160810                   395               1029   \n",
              "\n",
              "                                  params_encoder_name  params_max_new_tokens  \\\n",
              "0                           cointegrated/rubert-tiny2                    457   \n",
              "1                           cointegrated/rubert-tiny2                    322   \n",
              "2                           cointegrated/rubert-tiny2                    357   \n",
              "3                           cointegrated/rubert-tiny2                    507   \n",
              "4                           cointegrated/rubert-tiny2                    160   \n",
              "5   sentence-transformers/paraphrase-multilingual-...                    342   \n",
              "6                           cointegrated/rubert-tiny2                    356   \n",
              "7   sentence-transformers/paraphrase-multilingual-...                    804   \n",
              "8   sentence-transformers/paraphrase-multilingual-...                    183   \n",
              "9   sentence-transformers/paraphrase-multilingual-...                    397   \n",
              "10  sentence-transformers/paraphrase-multilingual-...                    801   \n",
              "11  sentence-transformers/paraphrase-multilingual-...                    637   \n",
              "12  sentence-transformers/paraphrase-multilingual-...                    561   \n",
              "13  sentence-transformers/paraphrase-multilingual-...                    640   \n",
              "\n",
              "    params_n_top_cos params_sep  params_temperature  params_top_k  \\\n",
              "0                  1         \\n            0.648665           105   \n",
              "1                  2                       0.562592            15   \n",
              "2                  6         \\n            0.053181           136   \n",
              "3                  6                       0.524387            32   \n",
              "4                  3                       0.569397            30   \n",
              "5                  3                       0.355345            16   \n",
              "6                  8          .            0.608458            70   \n",
              "7                  1          .            0.648490           121   \n",
              "8                  3                       0.149339            57   \n",
              "9                  3          .            0.091645            40   \n",
              "10                 5          .            0.969772            51   \n",
              "11                 4          .            0.252652            17   \n",
              "12                 4          .            0.269632            90   \n",
              "13                 5          .            0.340383            95   \n",
              "\n",
              "    params_top_p     state  \n",
              "0       0.863927  COMPLETE  \n",
              "1       0.122662  COMPLETE  \n",
              "2       0.575313  COMPLETE  \n",
              "3       0.104060  COMPLETE  \n",
              "4       0.957928  COMPLETE  \n",
              "5       0.905532  COMPLETE  \n",
              "6       0.868423  COMPLETE  \n",
              "7       0.174780  COMPLETE  \n",
              "8       0.269527  COMPLETE  \n",
              "9       0.713321  COMPLETE  \n",
              "10      0.591829  COMPLETE  \n",
              "11      0.724700  COMPLETE  \n",
              "12      0.683207  COMPLETE  \n",
              "13      0.389106      FAIL  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ba304c07-1bbc-4e25-b49e-6c889f576e95\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>number</th>\n",
              "      <th>value</th>\n",
              "      <th>datetime_start</th>\n",
              "      <th>datetime_complete</th>\n",
              "      <th>duration</th>\n",
              "      <th>params_chunk_overlap</th>\n",
              "      <th>params_chunk_size</th>\n",
              "      <th>params_encoder_name</th>\n",
              "      <th>params_max_new_tokens</th>\n",
              "      <th>params_n_top_cos</th>\n",
              "      <th>params_sep</th>\n",
              "      <th>params_temperature</th>\n",
              "      <th>params_top_k</th>\n",
              "      <th>params_top_p</th>\n",
              "      <th>state</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>44.508548</td>\n",
              "      <td>2024-09-29 15:33:43.639050</td>\n",
              "      <td>2024-09-29 15:34:46.717970</td>\n",
              "      <td>0 days 00:01:03.078920</td>\n",
              "      <td>110</td>\n",
              "      <td>1653</td>\n",
              "      <td>cointegrated/rubert-tiny2</td>\n",
              "      <td>457</td>\n",
              "      <td>1</td>\n",
              "      <td>\\n</td>\n",
              "      <td>0.648665</td>\n",
              "      <td>105</td>\n",
              "      <td>0.863927</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>55.324839</td>\n",
              "      <td>2024-09-29 15:34:46.718298</td>\n",
              "      <td>2024-09-29 15:35:55.938448</td>\n",
              "      <td>0 days 00:01:09.220150</td>\n",
              "      <td>521</td>\n",
              "      <td>1593</td>\n",
              "      <td>cointegrated/rubert-tiny2</td>\n",
              "      <td>322</td>\n",
              "      <td>2</td>\n",
              "      <td></td>\n",
              "      <td>0.562592</td>\n",
              "      <td>15</td>\n",
              "      <td>0.122662</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>47.795806</td>\n",
              "      <td>2024-09-29 15:35:55.938873</td>\n",
              "      <td>2024-09-29 15:37:02.157081</td>\n",
              "      <td>0 days 00:01:06.218208</td>\n",
              "      <td>469</td>\n",
              "      <td>751</td>\n",
              "      <td>cointegrated/rubert-tiny2</td>\n",
              "      <td>357</td>\n",
              "      <td>6</td>\n",
              "      <td>\\n</td>\n",
              "      <td>0.053181</td>\n",
              "      <td>136</td>\n",
              "      <td>0.575313</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>30.775806</td>\n",
              "      <td>2024-09-29 15:37:02.157319</td>\n",
              "      <td>2024-09-29 15:38:09.290714</td>\n",
              "      <td>0 days 00:01:07.133395</td>\n",
              "      <td>134</td>\n",
              "      <td>1425</td>\n",
              "      <td>cointegrated/rubert-tiny2</td>\n",
              "      <td>507</td>\n",
              "      <td>6</td>\n",
              "      <td></td>\n",
              "      <td>0.524387</td>\n",
              "      <td>32</td>\n",
              "      <td>0.104060</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>43.579032</td>\n",
              "      <td>2024-09-29 15:38:09.290954</td>\n",
              "      <td>2024-09-29 15:39:31.353000</td>\n",
              "      <td>0 days 00:01:22.062046</td>\n",
              "      <td>566</td>\n",
              "      <td>706</td>\n",
              "      <td>cointegrated/rubert-tiny2</td>\n",
              "      <td>160</td>\n",
              "      <td>3</td>\n",
              "      <td></td>\n",
              "      <td>0.569397</td>\n",
              "      <td>30</td>\n",
              "      <td>0.957928</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>58.064516</td>\n",
              "      <td>2024-09-29 15:39:31.353421</td>\n",
              "      <td>2024-09-29 15:41:28.949359</td>\n",
              "      <td>0 days 00:01:57.595938</td>\n",
              "      <td>105</td>\n",
              "      <td>744</td>\n",
              "      <td>sentence-transformers/paraphrase-multilingual-...</td>\n",
              "      <td>342</td>\n",
              "      <td>3</td>\n",
              "      <td></td>\n",
              "      <td>0.355345</td>\n",
              "      <td>16</td>\n",
              "      <td>0.905532</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>36.497742</td>\n",
              "      <td>2024-09-29 15:41:28.949619</td>\n",
              "      <td>2024-09-29 15:42:44.628772</td>\n",
              "      <td>0 days 00:01:15.679153</td>\n",
              "      <td>571</td>\n",
              "      <td>669</td>\n",
              "      <td>cointegrated/rubert-tiny2</td>\n",
              "      <td>356</td>\n",
              "      <td>8</td>\n",
              "      <td>.</td>\n",
              "      <td>0.608458</td>\n",
              "      <td>70</td>\n",
              "      <td>0.868423</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>44.472097</td>\n",
              "      <td>2024-09-29 15:42:44.629041</td>\n",
              "      <td>2024-09-29 15:44:39.669284</td>\n",
              "      <td>0 days 00:01:55.040243</td>\n",
              "      <td>299</td>\n",
              "      <td>1363</td>\n",
              "      <td>sentence-transformers/paraphrase-multilingual-...</td>\n",
              "      <td>804</td>\n",
              "      <td>1</td>\n",
              "      <td>.</td>\n",
              "      <td>0.648490</td>\n",
              "      <td>121</td>\n",
              "      <td>0.174780</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>45.559032</td>\n",
              "      <td>2024-09-29 15:44:39.669593</td>\n",
              "      <td>2024-09-29 15:46:34.648044</td>\n",
              "      <td>0 days 00:01:54.978451</td>\n",
              "      <td>198</td>\n",
              "      <td>1683</td>\n",
              "      <td>sentence-transformers/paraphrase-multilingual-...</td>\n",
              "      <td>183</td>\n",
              "      <td>3</td>\n",
              "      <td></td>\n",
              "      <td>0.149339</td>\n",
              "      <td>57</td>\n",
              "      <td>0.269527</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>64.518387</td>\n",
              "      <td>2024-09-29 15:46:34.648310</td>\n",
              "      <td>2024-09-29 15:49:41.909430</td>\n",
              "      <td>0 days 00:03:07.261120</td>\n",
              "      <td>538</td>\n",
              "      <td>722</td>\n",
              "      <td>sentence-transformers/paraphrase-multilingual-...</td>\n",
              "      <td>397</td>\n",
              "      <td>3</td>\n",
              "      <td>.</td>\n",
              "      <td>0.091645</td>\n",
              "      <td>40</td>\n",
              "      <td>0.713321</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>51.215645</td>\n",
              "      <td>2024-09-29 15:49:41.909749</td>\n",
              "      <td>2024-09-29 15:51:53.530972</td>\n",
              "      <td>0 days 00:02:11.621223</td>\n",
              "      <td>415</td>\n",
              "      <td>1052</td>\n",
              "      <td>sentence-transformers/paraphrase-multilingual-...</td>\n",
              "      <td>801</td>\n",
              "      <td>5</td>\n",
              "      <td>.</td>\n",
              "      <td>0.969772</td>\n",
              "      <td>51</td>\n",
              "      <td>0.591829</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>62.606613</td>\n",
              "      <td>2024-09-29 15:51:53.531209</td>\n",
              "      <td>2024-09-29 15:53:57.680767</td>\n",
              "      <td>0 days 00:02:04.149558</td>\n",
              "      <td>316</td>\n",
              "      <td>1039</td>\n",
              "      <td>sentence-transformers/paraphrase-multilingual-...</td>\n",
              "      <td>637</td>\n",
              "      <td>4</td>\n",
              "      <td>.</td>\n",
              "      <td>0.252652</td>\n",
              "      <td>17</td>\n",
              "      <td>0.724700</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>66.822419</td>\n",
              "      <td>2024-09-29 15:53:57.681160</td>\n",
              "      <td>2024-09-29 15:56:07.388938</td>\n",
              "      <td>0 days 00:02:09.707778</td>\n",
              "      <td>330</td>\n",
              "      <td>1029</td>\n",
              "      <td>sentence-transformers/paraphrase-multilingual-...</td>\n",
              "      <td>561</td>\n",
              "      <td>4</td>\n",
              "      <td>.</td>\n",
              "      <td>0.269632</td>\n",
              "      <td>90</td>\n",
              "      <td>0.683207</td>\n",
              "      <td>COMPLETE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2024-09-29 15:56:07.389207</td>\n",
              "      <td>2024-09-29 15:56:14.550017</td>\n",
              "      <td>0 days 00:00:07.160810</td>\n",
              "      <td>395</td>\n",
              "      <td>1029</td>\n",
              "      <td>sentence-transformers/paraphrase-multilingual-...</td>\n",
              "      <td>640</td>\n",
              "      <td>5</td>\n",
              "      <td>.</td>\n",
              "      <td>0.340383</td>\n",
              "      <td>95</td>\n",
              "      <td>0.389106</td>\n",
              "      <td>FAIL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba304c07-1bbc-4e25-b49e-6c889f576e95')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ba304c07-1bbc-4e25-b49e-6c889f576e95 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ba304c07-1bbc-4e25-b49e-6c889f576e95');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a648e5fe-2ae0-4cd5-a88c-3468fc76ebcf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a648e5fe-2ae0-4cd5-a88c-3468fc76ebcf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a648e5fe-2ae0-4cd5-a88c-3468fc76ebcf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "opuna_df",
              "summary": "{\n  \"name\": \"opuna_df\",\n  \"rows\": 14,\n  \"fields\": [\n    {\n      \"column\": \"number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 0,\n        \"max\": 13,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          9,\n          11,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10.900087845445169,\n        \"min\": 30.775806451612905,\n        \"max\": 66.8224193548387,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          62.60661290322581,\n          64.5183870967742,\n          44.50854838709678\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"datetime_start\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2024-09-29 15:33:43.639050\",\n        \"max\": \"2024-09-29 15:56:07.389207\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"2024-09-29 15:46:34.648310\",\n          \"2024-09-29 15:51:53.531209\",\n          \"2024-09-29 15:33:43.639050\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"datetime_complete\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2024-09-29 15:34:46.717970\",\n        \"max\": \"2024-09-29 15:56:14.550017\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"2024-09-29 15:49:41.909430\",\n          \"2024-09-29 15:53:57.680767\",\n          \"2024-09-29 15:34:46.717970\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"duration\",\n      \"properties\": {\n        \"dtype\": \"timedelta64[ns]\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"0 days 00:03:07.261120\",\n          \"0 days 00:02:04.149558\",\n          \"0 days 00:01:03.078920\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"params_chunk_overlap\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 169,\n        \"min\": 105,\n        \"max\": 571,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          538,\n          316,\n          110\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"params_chunk_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 373,\n        \"min\": 669,\n        \"max\": 1683,\n        \"num_unique_values\": 13,\n        \"samples\": [\n          1039,\n          722,\n          1653\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"params_encoder_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\",\n          \"cointegrated/rubert-tiny2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"params_max_new_tokens\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 202,\n        \"min\": 160,\n        \"max\": 804,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          397,\n          637\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"params_n_top_cos\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 8,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"params_sep\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"\\n\",\n          \" \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"params_temperature\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.258792376718119,\n        \"min\": 0.05318061106301074,\n        \"max\": 0.9697719820732436,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.09164500526772866,\n          0.2526523834702287\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"params_top_k\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 40,\n        \"min\": 15,\n        \"max\": 136,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          40,\n          17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"params_top_p\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3028884328395022,\n        \"min\": 0.10405978017370968,\n        \"max\": 0.9579279011218343,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.7133208850159373,\n          0.7247001207291337\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"state\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"FAIL\",\n          \"COMPLETE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74a26b66",
      "metadata": {
        "id": "74a26b66"
      },
      "source": [
        "# Результат"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "ad2139b0",
      "metadata": {
        "id": "ad2139b0",
        "outputId": "8d2602ad-d521-4e66-e7e3-352ec336bdb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "opuna_df['value'].plot(kind='hist', bins=40, figsize=(10, 4));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "e5a792cc",
      "metadata": {
        "id": "e5a792cc",
        "outputId": "48ba9371-f7c0-4516-e9ea-c2731c7fc76f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшее значение: 66.8224193548387\n",
            "Среднее значение: 50.13388337468984\n",
            "Медианное значение: 47.795806451612904\n"
          ]
        }
      ],
      "source": [
        "print('Лучшее значение:', study.best_value)\n",
        "print('Среднее значение:', opuna_df['value'].mean())\n",
        "print('Медианное значение:', opuna_df['value'].median())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "680be82e",
      "metadata": {
        "id": "680be82e",
        "outputId": "785c4a2f-7903-4961-d9bc-3e81ef06997b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'encoder_name': 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2',\n",
              " 'sep': '.',\n",
              " 'chunk_size': 1029,\n",
              " 'chunk_overlap': 330,\n",
              " 'n_top_cos': 4,\n",
              " 'max_new_tokens': 561,\n",
              " 'temperature': 0.2696322720540467,\n",
              " 'top_p': 0.6832065754969388,\n",
              " 'top_k': 90}"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ],
      "source": [
        "study.best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "56b54bcd",
      "metadata": {
        "id": "56b54bcd",
        "outputId": "8588c19e-9f2f-43d8-a25c-dc6518128b09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              Вопрос   Правильный ответ  \\\n",
              "0          Какой город является столицей Свазиленда?            Мбабане   \n",
              "1    В каком городе пребывает Международный суд ООН?              Гаага   \n",
              "2                            Какая столица Вьетнама?              Ханой   \n",
              "3                            Чья песня Sweet dreams?         Eurythmics   \n",
              "4                На каких языках говорят в Тайланде?       Тайский язык   \n",
              "5                       Когда упразднили ФМС России?        в 2016 году   \n",
              "6  Где происходит оплодотворение яйцеклетки у жен...  В маточных трубах   \n",
              "7  Кто сыграл главного героя в фильме \"Форрест Га...              Хэнкс   \n",
              "8              Какая гора - наивысшая точка Кавказа?            Эльбрус   \n",
              "9  Какая страна является местом проведения Зимних...              Корея   \n",
              "\n",
              "                                               Ответ  file_score  \\\n",
              "0        Столицей Свазиленда является город Мбабане.           1   \n",
              "1  Международный суд ООН пребывает в Гааге, Нидер...           1   \n",
              "2                  Столицей Вьетнама является Ханой.           1   \n",
              "3  Песня \"Sweet Dreams\" принадлежит британскому п...           1   \n",
              "4               В Таиланде говорят на тайском языке.           1   \n",
              "5     ФМС России была упразднена 5 апреля 2016 года.           1   \n",
              "6  Оплодотворение яйцеклетки у женщины происходит...           1   \n",
              "7  Том Хэнкс сыграл главного героя в фильме \"Форр...           1   \n",
              "8  Наивысшей точкой Кавказа является гора Эльбрус...           1   \n",
              "9  Зимние Олимпийские игры 2018 года проходили в ...           1   \n",
              "\n",
              "   context_score  llm_score  \n",
              "0            100      100.0  \n",
              "1            100      100.0  \n",
              "2            100      100.0  \n",
              "3            100      100.0  \n",
              "4            100      100.0  \n",
              "5            100      100.0  \n",
              "6            100      100.0  \n",
              "7             98      100.0  \n",
              "8             97      100.0  \n",
              "9             97      100.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f01c6c07-8d32-48b9-ab68-7a92d8d47ced\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Вопрос</th>\n",
              "      <th>Правильный ответ</th>\n",
              "      <th>Ответ</th>\n",
              "      <th>file_score</th>\n",
              "      <th>context_score</th>\n",
              "      <th>llm_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Какой город является столицей Свазиленда?</td>\n",
              "      <td>Мбабане</td>\n",
              "      <td>Столицей Свазиленда является город Мбабане.</td>\n",
              "      <td>1</td>\n",
              "      <td>100</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>В каком городе пребывает Международный суд ООН?</td>\n",
              "      <td>Гаага</td>\n",
              "      <td>Международный суд ООН пребывает в Гааге, Нидер...</td>\n",
              "      <td>1</td>\n",
              "      <td>100</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Какая столица Вьетнама?</td>\n",
              "      <td>Ханой</td>\n",
              "      <td>Столицей Вьетнама является Ханой.</td>\n",
              "      <td>1</td>\n",
              "      <td>100</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Чья песня Sweet dreams?</td>\n",
              "      <td>Eurythmics</td>\n",
              "      <td>Песня \"Sweet Dreams\" принадлежит британскому п...</td>\n",
              "      <td>1</td>\n",
              "      <td>100</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>На каких языках говорят в Тайланде?</td>\n",
              "      <td>Тайский язык</td>\n",
              "      <td>В Таиланде говорят на тайском языке.</td>\n",
              "      <td>1</td>\n",
              "      <td>100</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Когда упразднили ФМС России?</td>\n",
              "      <td>в 2016 году</td>\n",
              "      <td>ФМС России была упразднена 5 апреля 2016 года.</td>\n",
              "      <td>1</td>\n",
              "      <td>100</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Где происходит оплодотворение яйцеклетки у жен...</td>\n",
              "      <td>В маточных трубах</td>\n",
              "      <td>Оплодотворение яйцеклетки у женщины происходит...</td>\n",
              "      <td>1</td>\n",
              "      <td>100</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Кто сыграл главного героя в фильме \"Форрест Га...</td>\n",
              "      <td>Хэнкс</td>\n",
              "      <td>Том Хэнкс сыграл главного героя в фильме \"Форр...</td>\n",
              "      <td>1</td>\n",
              "      <td>98</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Какая гора - наивысшая точка Кавказа?</td>\n",
              "      <td>Эльбрус</td>\n",
              "      <td>Наивысшей точкой Кавказа является гора Эльбрус...</td>\n",
              "      <td>1</td>\n",
              "      <td>97</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Какая страна является местом проведения Зимних...</td>\n",
              "      <td>Корея</td>\n",
              "      <td>Зимние Олимпийские игры 2018 года проходили в ...</td>\n",
              "      <td>1</td>\n",
              "      <td>97</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f01c6c07-8d32-48b9-ab68-7a92d8d47ced')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f01c6c07-8d32-48b9-ab68-7a92d8d47ced button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f01c6c07-8d32-48b9-ab68-7a92d8d47ced');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-118482b5-8e7a-46bd-9a2d-79455b468b32\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-118482b5-8e7a-46bd-9a2d-79455b468b32')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-118482b5-8e7a-46bd-9a2d-79455b468b32 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"best_result[cols]\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"\\u0412\\u043e\\u043f\\u0440\\u043e\\u0441\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"\\u041a\\u0430\\u043a\\u0430\\u044f \\u0433\\u043e\\u0440\\u0430 - \\u043d\\u0430\\u0438\\u0432\\u044b\\u0441\\u0448\\u0430\\u044f \\u0442\\u043e\\u0447\\u043a\\u0430 \\u041a\\u0430\\u0432\\u043a\\u0430\\u0437\\u0430?\",\n          \"\\u0412 \\u043a\\u0430\\u043a\\u043e\\u043c \\u0433\\u043e\\u0440\\u043e\\u0434\\u0435 \\u043f\\u0440\\u0435\\u0431\\u044b\\u0432\\u0430\\u0435\\u0442 \\u041c\\u0435\\u0436\\u0434\\u0443\\u043d\\u0430\\u0440\\u043e\\u0434\\u043d\\u044b\\u0439 \\u0441\\u0443\\u0434 \\u041e\\u041e\\u041d?\",\n          \"\\u041a\\u043e\\u0433\\u0434\\u0430 \\u0443\\u043f\\u0440\\u0430\\u0437\\u0434\\u043d\\u0438\\u043b\\u0438 \\u0424\\u041c\\u0421 \\u0420\\u043e\\u0441\\u0441\\u0438\\u0438?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u041f\\u0440\\u0430\\u0432\\u0438\\u043b\\u044c\\u043d\\u044b\\u0439 \\u043e\\u0442\\u0432\\u0435\\u0442\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"\\u042d\\u043b\\u044c\\u0431\\u0440\\u0443\\u0441\",\n          \"\\u0413\\u0430\\u0430\\u0433\\u0430\",\n          \"\\u0432 2016 \\u0433\\u043e\\u0434\\u0443\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u041e\\u0442\\u0432\\u0435\\u0442\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"\\u041d\\u0430\\u0438\\u0432\\u044b\\u0441\\u0448\\u0435\\u0439 \\u0442\\u043e\\u0447\\u043a\\u043e\\u0439 \\u041a\\u0430\\u0432\\u043a\\u0430\\u0437\\u0430 \\u044f\\u0432\\u043b\\u044f\\u0435\\u0442\\u0441\\u044f \\u0433\\u043e\\u0440\\u0430 \\u042d\\u043b\\u044c\\u0431\\u0440\\u0443\\u0441, \\u0432\\u044b\\u0441\\u043e\\u0442\\u043e\\u0439 5642 \\u043c\\u0435\\u0442\\u0440\\u0430.\",\n          \"\\u041c\\u0435\\u0436\\u0434\\u0443\\u043d\\u0430\\u0440\\u043e\\u0434\\u043d\\u044b\\u0439 \\u0441\\u0443\\u0434 \\u041e\\u041e\\u041d \\u043f\\u0440\\u0435\\u0431\\u044b\\u0432\\u0430\\u0435\\u0442 \\u0432 \\u0413\\u0430\\u0430\\u0433\\u0435, \\u041d\\u0438\\u0434\\u0435\\u0440\\u043b\\u0430\\u043d\\u0434\\u044b.\",\n          \"\\u0424\\u041c\\u0421 \\u0420\\u043e\\u0441\\u0441\\u0438\\u0438 \\u0431\\u044b\\u043b\\u0430 \\u0443\\u043f\\u0440\\u0430\\u0437\\u0434\\u043d\\u0435\\u043d\\u0430 5 \\u0430\\u043f\\u0440\\u0435\\u043b\\u044f 2016 \\u0433\\u043e\\u0434\\u0430.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 97,\n        \"max\": 100,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          100\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"llm_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 100.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          100.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "cols = ['Вопрос', 'Правильный ответ', 'Ответ', 'file_score', 'context_score', 'llm_score']\n",
        "best_result[cols].head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "83f62046",
      "metadata": {
        "scrolled": false,
        "id": "83f62046",
        "outputId": "296e966d-d6a3-42b3-c958-e239befd90af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 860
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Вопрос  \\\n",
              "50         Как называется самая высокая гора Украины?   \n",
              "51      В каком году обнаружили реликтовое излучение?   \n",
              "52                     Когда началась Первая мировая?   \n",
              "53  Что стало причиной смерти английского мореплав...   \n",
              "54           В каком году завершилась Первая мировая?   \n",
              "55             В каком году построена Эйфелева башня?   \n",
              "56                    Когда закончились Средние века?   \n",
              "57           К какой династии принадлежал Людовик 18?   \n",
              "58                Когда написан Герой нашего времени?   \n",
              "59                      Как мать Григория Перельмана?   \n",
              "60                       Сколько сезонов в Ворониных?   \n",
              "61                  В каком направлении писал Тютчев?   \n",
              "\n",
              "              Правильный ответ  \\\n",
              "50                     говерла   \n",
              "51                        1948   \n",
              "52              28 июля 1914 г   \n",
              "53                  Дизентерия   \n",
              "54              11 ноября 1918   \n",
              "55            28 января 1887 г   \n",
              "56                    1500 год   \n",
              "57                    Юурбонов   \n",
              "58                      1839 г   \n",
              "59  Любовь Лейбовна Штейнгольц   \n",
              "60                          24   \n",
              "61         романтизм, пантеизм   \n",
              "\n",
              "                                                Ответ  file_score  \\\n",
              "50  Что-то в вашем вопросе меня смущает. Может, по...           1   \n",
              "51     Реликтовое излучение было открыто в 1965 году.           1   \n",
              "52  Как у нейросетевой языковой модели у меня не м...           1   \n",
              "53  Не люблю менять тему разговора, но вот сейчас ...           1   \n",
              "54  Не люблю менять тему разговора, но вот сейчас ...           1   \n",
              "55         Эйфелева башня была построена в 1889 году.           1   \n",
              "56  Средние века закончились в конце XVIII века, с...           1   \n",
              "57   Людовик XVIII принадлежал к Бурбонской династии.           1   \n",
              "58  Роман \"Герой нашего времени\" был написан Михаи...           0   \n",
              "59  Извините, но в предоставленном вами контексте ...           0   \n",
              "60  Извините, но в контексте не указано количество...           0   \n",
              "61  Не люблю менять тему разговора, но вот сейчас ...           1   \n",
              "\n",
              "    context_score  llm_score  \n",
              "50             92        0.0  \n",
              "51             39        0.0  \n",
              "52             39        0.0  \n",
              "53             34        0.0  \n",
              "54             34        0.0  \n",
              "55             33        0.0  \n",
              "56             29        0.0  \n",
              "57             26        0.0  \n",
              "58             22        0.0  \n",
              "59             14        0.0  \n",
              "60              7        0.0  \n",
              "61              6        0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-01688bee-4e6f-42a9-88d5-85ea7e3a3536\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Вопрос</th>\n",
              "      <th>Правильный ответ</th>\n",
              "      <th>Ответ</th>\n",
              "      <th>file_score</th>\n",
              "      <th>context_score</th>\n",
              "      <th>llm_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Как называется самая высокая гора Украины?</td>\n",
              "      <td>говерла</td>\n",
              "      <td>Что-то в вашем вопросе меня смущает. Может, по...</td>\n",
              "      <td>1</td>\n",
              "      <td>92</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>В каком году обнаружили реликтовое излучение?</td>\n",
              "      <td>1948</td>\n",
              "      <td>Реликтовое излучение было открыто в 1965 году.</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>Когда началась Первая мировая?</td>\n",
              "      <td>28 июля 1914 г</td>\n",
              "      <td>Как у нейросетевой языковой модели у меня не м...</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>Что стало причиной смерти английского мореплав...</td>\n",
              "      <td>Дизентерия</td>\n",
              "      <td>Не люблю менять тему разговора, но вот сейчас ...</td>\n",
              "      <td>1</td>\n",
              "      <td>34</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>В каком году завершилась Первая мировая?</td>\n",
              "      <td>11 ноября 1918</td>\n",
              "      <td>Не люблю менять тему разговора, но вот сейчас ...</td>\n",
              "      <td>1</td>\n",
              "      <td>34</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>В каком году построена Эйфелева башня?</td>\n",
              "      <td>28 января 1887 г</td>\n",
              "      <td>Эйфелева башня была построена в 1889 году.</td>\n",
              "      <td>1</td>\n",
              "      <td>33</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>Когда закончились Средние века?</td>\n",
              "      <td>1500 год</td>\n",
              "      <td>Средние века закончились в конце XVIII века, с...</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>К какой династии принадлежал Людовик 18?</td>\n",
              "      <td>Юурбонов</td>\n",
              "      <td>Людовик XVIII принадлежал к Бурбонской династии.</td>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>Когда написан Герой нашего времени?</td>\n",
              "      <td>1839 г</td>\n",
              "      <td>Роман \"Герой нашего времени\" был написан Михаи...</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>Как мать Григория Перельмана?</td>\n",
              "      <td>Любовь Лейбовна Штейнгольц</td>\n",
              "      <td>Извините, но в предоставленном вами контексте ...</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>Сколько сезонов в Ворониных?</td>\n",
              "      <td>24</td>\n",
              "      <td>Извините, но в контексте не указано количество...</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>В каком направлении писал Тютчев?</td>\n",
              "      <td>романтизм, пантеизм</td>\n",
              "      <td>Не люблю менять тему разговора, но вот сейчас ...</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01688bee-4e6f-42a9-88d5-85ea7e3a3536')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-01688bee-4e6f-42a9-88d5-85ea7e3a3536 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-01688bee-4e6f-42a9-88d5-85ea7e3a3536');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9ee7238f-43ec-4163-9a4a-4e7f8f68dad3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9ee7238f-43ec-4163-9a4a-4e7f8f68dad3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9ee7238f-43ec-4163-9a4a-4e7f8f68dad3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"best_result[cols]\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"\\u0412\\u043e\\u043f\\u0440\\u043e\\u0441\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"\\u0421\\u043a\\u043e\\u043b\\u044c\\u043a\\u043e \\u0441\\u0435\\u0437\\u043e\\u043d\\u043e\\u0432 \\u0432 \\u0412\\u043e\\u0440\\u043e\\u043d\\u0438\\u043d\\u044b\\u0445?\",\n          \"\\u041a\\u0430\\u043a \\u043c\\u0430\\u0442\\u044c \\u0413\\u0440\\u0438\\u0433\\u043e\\u0440\\u0438\\u044f \\u041f\\u0435\\u0440\\u0435\\u043b\\u044c\\u043c\\u0430\\u043d\\u0430?\",\n          \"\\u041a\\u0430\\u043a \\u043d\\u0430\\u0437\\u044b\\u0432\\u0430\\u0435\\u0442\\u0441\\u044f \\u0441\\u0430\\u043c\\u0430\\u044f \\u0432\\u044b\\u0441\\u043e\\u043a\\u0430\\u044f \\u0433\\u043e\\u0440\\u0430 \\u0423\\u043a\\u0440\\u0430\\u0438\\u043d\\u044b?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u041f\\u0440\\u0430\\u0432\\u0438\\u043b\\u044c\\u043d\\u044b\\u0439 \\u043e\\u0442\\u0432\\u0435\\u0442\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"24\",\n          \"\\u041b\\u044e\\u0431\\u043e\\u0432\\u044c \\u041b\\u0435\\u0439\\u0431\\u043e\\u0432\\u043d\\u0430 \\u0428\\u0442\\u0435\\u0439\\u043d\\u0433\\u043e\\u043b\\u044c\\u0446\",\n          \"\\u0433\\u043e\\u0432\\u0435\\u0440\\u043b\\u0430\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u041e\\u0442\\u0432\\u0435\\u0442\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"\\u0418\\u0437\\u0432\\u0438\\u043d\\u0438\\u0442\\u0435, \\u043d\\u043e \\u0432 \\u043f\\u0440\\u0435\\u0434\\u043e\\u0441\\u0442\\u0430\\u0432\\u043b\\u0435\\u043d\\u043d\\u043e\\u043c \\u0432\\u0430\\u043c\\u0438 \\u043a\\u043e\\u043d\\u0442\\u0435\\u043a\\u0441\\u0442\\u0435 \\u043d\\u0435\\u0442 \\u0438\\u043d\\u0444\\u043e\\u0440\\u043c\\u0430\\u0446\\u0438\\u0438 \\u043e \\u043c\\u0430\\u0442\\u0435\\u0440\\u0438 \\u0413\\u0440\\u0438\\u0433\\u043e\\u0440\\u0438\\u044f \\u041f\\u0435\\u0440\\u0435\\u043b\\u044c\\u043c\\u0430\\u043d\\u0430.\",\n          \"\\u0420\\u0435\\u043b\\u0438\\u043a\\u0442\\u043e\\u0432\\u043e\\u0435 \\u0438\\u0437\\u043b\\u0443\\u0447\\u0435\\u043d\\u0438\\u0435 \\u0431\\u044b\\u043b\\u043e \\u043e\\u0442\\u043a\\u0440\\u044b\\u0442\\u043e \\u0432 1965 \\u0433\\u043e\\u0434\\u0443.\",\n          \"\\u0421\\u0440\\u0435\\u0434\\u043d\\u0438\\u0435 \\u0432\\u0435\\u043a\\u0430 \\u0437\\u0430\\u043a\\u043e\\u043d\\u0447\\u0438\\u043b\\u0438\\u0441\\u044c \\u0432 \\u043a\\u043e\\u043d\\u0446\\u0435 XVIII \\u0432\\u0435\\u043a\\u0430, \\u0441\\u043e\\u0433\\u043b\\u0430\\u0441\\u043d\\u043e \\u0444\\u0440\\u0430\\u043d\\u0446\\u0443\\u0437\\u0441\\u043a\\u043e\\u0439 \\u0442\\u0435\\u043e\\u0440\\u0438\\u0438 \\\"\\u0434\\u043e\\u043b\\u0433\\u043e\\u0433\\u043e \\u0421\\u0440\\u0435\\u0434\\u043d\\u0435\\u0432\\u0435\\u043a\\u043e\\u0432\\u044c\\u044f\\\".\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22,\n        \"min\": 6,\n        \"max\": 92,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          7,\n          39\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"llm_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "cols = ['Вопрос', 'Правильный ответ', 'Ответ', 'file_score', 'context_score', 'llm_score']\n",
        "best_result[cols].tail(12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "8697d32b",
      "metadata": {
        "scrolled": false,
        "id": "8697d32b",
        "outputId": "b06c29a3-778e-485a-db28-68c4d2fbd8fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                      12  \\\n",
              "value                                                          66.822419   \n",
              "params_chunk_overlap                                                 330   \n",
              "params_chunk_size                                                   1029   \n",
              "params_encoder_name    sentence-transformers/paraphrase-multilingual-...   \n",
              "params_max_new_tokens                                                561   \n",
              "params_sep                                                             .   \n",
              "params_temperature                                              0.269632   \n",
              "params_n_top_cos                                                       4   \n",
              "params_top_k                                                          90   \n",
              "params_top_p                                                    0.683207   \n",
              "\n",
              "                                                                      9   \\\n",
              "value                                                          64.518387   \n",
              "params_chunk_overlap                                                 538   \n",
              "params_chunk_size                                                    722   \n",
              "params_encoder_name    sentence-transformers/paraphrase-multilingual-...   \n",
              "params_max_new_tokens                                                397   \n",
              "params_sep                                                             .   \n",
              "params_temperature                                              0.091645   \n",
              "params_n_top_cos                                                       3   \n",
              "params_top_k                                                          40   \n",
              "params_top_p                                                    0.713321   \n",
              "\n",
              "                                                                      11  \\\n",
              "value                                                          62.606613   \n",
              "params_chunk_overlap                                                 316   \n",
              "params_chunk_size                                                   1039   \n",
              "params_encoder_name    sentence-transformers/paraphrase-multilingual-...   \n",
              "params_max_new_tokens                                                637   \n",
              "params_sep                                                             .   \n",
              "params_temperature                                              0.252652   \n",
              "params_n_top_cos                                                       4   \n",
              "params_top_k                                                          17   \n",
              "params_top_p                                                      0.7247   \n",
              "\n",
              "                                                                      5   \\\n",
              "value                                                          58.064516   \n",
              "params_chunk_overlap                                                 105   \n",
              "params_chunk_size                                                    744   \n",
              "params_encoder_name    sentence-transformers/paraphrase-multilingual-...   \n",
              "params_max_new_tokens                                                342   \n",
              "params_sep                                                                 \n",
              "params_temperature                                              0.355345   \n",
              "params_n_top_cos                                                       3   \n",
              "params_top_k                                                          16   \n",
              "params_top_p                                                    0.905532   \n",
              "\n",
              "                                              1   \\\n",
              "value                                  55.324839   \n",
              "params_chunk_overlap                         521   \n",
              "params_chunk_size                           1593   \n",
              "params_encoder_name    cointegrated/rubert-tiny2   \n",
              "params_max_new_tokens                        322   \n",
              "params_sep                                         \n",
              "params_temperature                      0.562592   \n",
              "params_n_top_cos                               2   \n",
              "params_top_k                                  15   \n",
              "params_top_p                            0.122662   \n",
              "\n",
              "                                                                      10  \\\n",
              "value                                                          51.215645   \n",
              "params_chunk_overlap                                                 415   \n",
              "params_chunk_size                                                   1052   \n",
              "params_encoder_name    sentence-transformers/paraphrase-multilingual-...   \n",
              "params_max_new_tokens                                                801   \n",
              "params_sep                                                             .   \n",
              "params_temperature                                              0.969772   \n",
              "params_n_top_cos                                                       5   \n",
              "params_top_k                                                          51   \n",
              "params_top_p                                                    0.591829   \n",
              "\n",
              "                                              2   \\\n",
              "value                                  47.795806   \n",
              "params_chunk_overlap                         469   \n",
              "params_chunk_size                            751   \n",
              "params_encoder_name    cointegrated/rubert-tiny2   \n",
              "params_max_new_tokens                        357   \n",
              "params_sep                                    \\n   \n",
              "params_temperature                      0.053181   \n",
              "params_n_top_cos                               6   \n",
              "params_top_k                                 136   \n",
              "params_top_p                            0.575313   \n",
              "\n",
              "                                                                      8   \\\n",
              "value                                                          45.559032   \n",
              "params_chunk_overlap                                                 198   \n",
              "params_chunk_size                                                   1683   \n",
              "params_encoder_name    sentence-transformers/paraphrase-multilingual-...   \n",
              "params_max_new_tokens                                                183   \n",
              "params_sep                                                                 \n",
              "params_temperature                                              0.149339   \n",
              "params_n_top_cos                                                       3   \n",
              "params_top_k                                                          57   \n",
              "params_top_p                                                    0.269527   \n",
              "\n",
              "                                              0   \n",
              "value                                  44.508548  \n",
              "params_chunk_overlap                         110  \n",
              "params_chunk_size                           1653  \n",
              "params_encoder_name    cointegrated/rubert-tiny2  \n",
              "params_max_new_tokens                        457  \n",
              "params_sep                                    \\n  \n",
              "params_temperature                      0.648665  \n",
              "params_n_top_cos                               1  \n",
              "params_top_k                                 105  \n",
              "params_top_p                            0.863927  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9707ae80-7f9d-401e-820b-ad498c90ecfd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>12</th>\n",
              "      <th>9</th>\n",
              "      <th>11</th>\n",
              "      <th>5</th>\n",
              "      <th>1</th>\n",
              "      <th>10</th>\n",
              "      <th>2</th>\n",
              "      <th>8</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>value</th>\n",
              "      <td>66.822419</td>\n",
              "      <td>64.518387</td>\n",
              "      <td>62.606613</td>\n",
              "      <td>58.064516</td>\n",
              "      <td>55.324839</td>\n",
              "      <td>51.215645</td>\n",
              "      <td>47.795806</td>\n",
              "      <td>45.559032</td>\n",
              "      <td>44.508548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>params_chunk_overlap</th>\n",
              "      <td>330</td>\n",
              "      <td>538</td>\n",
              "      <td>316</td>\n",
              "      <td>105</td>\n",
              "      <td>521</td>\n",
              "      <td>415</td>\n",
              "      <td>469</td>\n",
              "      <td>198</td>\n",
              "      <td>110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>params_chunk_size</th>\n",
              "      <td>1029</td>\n",
              "      <td>722</td>\n",
              "      <td>1039</td>\n",
              "      <td>744</td>\n",
              "      <td>1593</td>\n",
              "      <td>1052</td>\n",
              "      <td>751</td>\n",
              "      <td>1683</td>\n",
              "      <td>1653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>params_encoder_name</th>\n",
              "      <td>sentence-transformers/paraphrase-multilingual-...</td>\n",
              "      <td>sentence-transformers/paraphrase-multilingual-...</td>\n",
              "      <td>sentence-transformers/paraphrase-multilingual-...</td>\n",
              "      <td>sentence-transformers/paraphrase-multilingual-...</td>\n",
              "      <td>cointegrated/rubert-tiny2</td>\n",
              "      <td>sentence-transformers/paraphrase-multilingual-...</td>\n",
              "      <td>cointegrated/rubert-tiny2</td>\n",
              "      <td>sentence-transformers/paraphrase-multilingual-...</td>\n",
              "      <td>cointegrated/rubert-tiny2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>params_max_new_tokens</th>\n",
              "      <td>561</td>\n",
              "      <td>397</td>\n",
              "      <td>637</td>\n",
              "      <td>342</td>\n",
              "      <td>322</td>\n",
              "      <td>801</td>\n",
              "      <td>357</td>\n",
              "      <td>183</td>\n",
              "      <td>457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>params_sep</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>.</td>\n",
              "      <td>\\n</td>\n",
              "      <td></td>\n",
              "      <td>\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>params_temperature</th>\n",
              "      <td>0.269632</td>\n",
              "      <td>0.091645</td>\n",
              "      <td>0.252652</td>\n",
              "      <td>0.355345</td>\n",
              "      <td>0.562592</td>\n",
              "      <td>0.969772</td>\n",
              "      <td>0.053181</td>\n",
              "      <td>0.149339</td>\n",
              "      <td>0.648665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>params_n_top_cos</th>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>params_top_k</th>\n",
              "      <td>90</td>\n",
              "      <td>40</td>\n",
              "      <td>17</td>\n",
              "      <td>16</td>\n",
              "      <td>15</td>\n",
              "      <td>51</td>\n",
              "      <td>136</td>\n",
              "      <td>57</td>\n",
              "      <td>105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>params_top_p</th>\n",
              "      <td>0.683207</td>\n",
              "      <td>0.713321</td>\n",
              "      <td>0.7247</td>\n",
              "      <td>0.905532</td>\n",
              "      <td>0.122662</td>\n",
              "      <td>0.591829</td>\n",
              "      <td>0.575313</td>\n",
              "      <td>0.269527</td>\n",
              "      <td>0.863927</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9707ae80-7f9d-401e-820b-ad498c90ecfd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9707ae80-7f9d-401e-820b-ad498c90ecfd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9707ae80-7f9d-401e-820b-ad498c90ecfd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e03e88a0-21c4-40e3-b18b-12e9ee20db75\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e03e88a0-21c4-40e3-b18b-12e9ee20db75')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e03e88a0-21c4-40e3-b18b-12e9ee20db75 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"opuna_df[cols]\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": 12,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          90,\n          330,\n          \".\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 9,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          40,\n          538,\n          \".\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 11,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          17,\n          316,\n          \".\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 5,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          16,\n          105,\n          \" \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          15,\n          521,\n          \" \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 10,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          51,\n          415,\n          \".\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          136,\n          469,\n          \"\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 8,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          57,\n          198,\n          \" \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          105,\n          110,\n          \"\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "cols = ['value', 'params_chunk_overlap', 'params_chunk_size', 'params_encoder_name',\n",
        "       'params_max_new_tokens', 'params_sep', 'params_temperature',\n",
        "       'params_n_top_cos', 'params_top_k', 'params_top_p']\n",
        "opuna_df[cols].sort_values(by='value', ascending=False).head(9).T"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "vyacheslav.koloskov_llm:latest",
      "language": "python",
      "name": "llm"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}